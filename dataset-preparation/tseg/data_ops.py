import re
import shutil
from pathlib import Path

import numpy as np
import polars as pl
from loguru import logger
from tqdm import tqdm

from . import image_ops, utils

CONFIG = utils.load_yaml()


def categorize_tiles(tile_folders_path: Path) -> dict:
    """Categorize tiled slide folders based on QuPath type."""
    logger.info("Categorizing tiled slides")
    categorized_tile_folders = {
        category: list(
            filter(
                lambda x: str(x.stem).split("|")[0] == category,
                tile_folders_path.iterdir(),
            )
        )
        for category in CONFIG["data_categories"]
    }

    category_details = ", ".join(
        f"{k}: {len(v)}" for k, v in categorized_tile_folders.items()
    )
    logger.info(f"Categories - {category_details}")
    return categorized_tile_folders


def extract_slide_info(slide_folder_paths: list) -> list:
    """Extract slide information from slide folder name."""
    
    column_names = [
        "category",
        "slide_name",
        "downsample_rate",
        "img_size",
        "overlap_ratio_per_tile",
        "only_annotated_tiles",
        "allow_partial_tiles",
        "tile_count",
        "mask_count",
    ]

    dataset_entries = []
    for folder_path in slide_folder_paths:
        split_folder_name = folder_path.name.split("|")

        tile_count = len([*(folder_path / "images").iterdir()])
        mask_count = len([*(folder_path / "masks").iterdir()])
        slide_info = dict(
            zip(column_names, split_folder_name + [tile_count, mask_count])
        )
        dataset_entries.append(slide_info)

    return dataset_entries


def extract_location_info(filename: str) -> dict:
    """Extract tile location information from tile file name generated by QuPath."""
    
    match = re.search(r"d=([\d.]+).*x=(\d+).*y=(\d+).*w=(\d+).*h=(\d+)", filename)
    if match:
        assert match.group(4) == match.group(5)
        return {
            "downsample_rate": float(match.group(1)),
            "x": match.group(2),
            "y": match.group(3),
            "size_on_slide": match.group(4),
        }
    return {}


def extract_tile_info(source: Path, suffix: str = "label", ext: str = "png") -> list:
    """Extract tile & mask information from file name and mask."""
    
    tile_info_entries = []

    for item in (source / "images").iterdir():
        if item.is_file():
            slide_dir_path = source
            mask_name = f"{item.stem}_{suffix}.{ext}"

            entry = {
                "slide_name": str(slide_dir_path.name),
                "parent_dir_path": str(slide_dir_path.relative_to(source.parent.parent)),
                "relative_image_path": str(item.relative_to(slide_dir_path)),
                "relative_mask_path": str(Path("masks") / mask_name),
            }

            full_mask_path = slide_dir_path / entry["relative_mask_path"]
            entry["tumor_percentage"] = str(
                image_ops.calculate_tumor_percentage(full_mask_path)
            )
            entry["image_size"] = str(image_ops.get_size(item))

            entry = entry | extract_location_info(item.name)
            tile_info_entries.append(entry)

    return tile_info_entries


def _construct_dataset_list(split: str, tiles: list) -> list:
    """Helper function for split_tiles."""
    
    return [
        {"full_path": path, "slide_name": path.name.split("|")[1], "split": split}
        for path in tiles
    ]


def split_tiles(source: Path, train_ratio: float, val_ratio: float, save_dir: Path) -> pl.DataFrame:
    """Split tiled WSI slides into train-val-test sets virtually. Extract slide and split metadata."""
    
    categories = categorize_tiles(source)

    logger.info("Creating slide and train-test-split metadata")
    create_test_set = False if np.isclose(train_ratio + val_ratio, 1) else True

    split_entries, slide_info_entries = [], []
    for tile_folders in categories.values():
        np.random.shuffle(tile_folders)
        slide_info_entries.extend(extract_slide_info(tile_folders))

        n_train = int(round(len(tile_folders) * train_ratio))
        n_val = int(round(len(tile_folders) * val_ratio))

        split_entries.extend(_construct_dataset_list("train", tile_folders[:n_train]))

        if create_test_set:
            split_entries.extend(
                _construct_dataset_list("val", tile_folders[n_train : n_train + n_val])
            )
            split_entries.extend(
                _construct_dataset_list("test", tile_folders[n_train + n_val :])
            )
        else:
            split_entries.extend(_construct_dataset_list("val", tile_folders[n_train:]))

    # Save slide information
    utils.save_csv(slide_info_entries, save_dir / "slide_info.csv")

    return pl.DataFrame(split_entries)


def construct_dataset(source: Path, split_info_df: pl.DataFrame, dirs: dict) -> None:
    """Copy files according to CSV file containing split information. Extracts tile metadata."""
    
    logger.info(f"Started constructing dataset at {dirs['parent']}/")
    all_tile_info_entries = []

    pbar = tqdm(
        split_info_df.iter_rows(named=True),
        total=len(split_info_df),
        position=0,
        leave=True,
        ncols=100,
    )
    for row_dict in pbar:
        current_slide_name = row_dict["slide_name"]
        pbar.set_description(f"Processing Slides | {utils.pad_str(current_slide_name)}")

        target_path = dirs[row_dict["split"]] / current_slide_name
        shutil.copytree(row_dict["full_path"], target_path)

        utils.add_suffix_to_dir_items(target_path / "masks")
        tile_info_entries = extract_tile_info(target_path)
        all_tile_info_entries.extend(tile_info_entries)
    
    # Remove temporary full path
    split_info_df.drop_in_place("full_path")
    
    # Save split information
    split_info_df.write_csv(dirs["metadata"] / "split_info.csv")
    
    # Save tile information
    utils.save_csv(all_tile_info_entries, dirs["metadata"] / "tile_info.csv")

    logger.info(f"Dataset constructed at {dirs['parent']}/")
    logger.info(f"Metadata saved at {dirs['metadata']}/")
