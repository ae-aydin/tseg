import re
import shutil
from pathlib import Path

import numpy as np
import polars as pl
from loguru import logger
from tqdm import tqdm

from . import image_ops, utils

CONFIG = utils.load_yaml()


def categorize_tiles(tile_folders_path: Path) -> dict:
    """Categorize tiled slide folders based on QuPath type.

    Args:
        tile_folders_path (Path): Path containing all tiled slide folders.

    Returns:
        dict: Categorized slides.
    """
    logger.info("Categorizing tiled slides")
    categorized_tile_folders = {
        category: list(
            filter(
                lambda x: str(x.stem).split("|")[0] == category,
                tile_folders_path.iterdir(),
            )
        )
        for category in CONFIG["data_categories"]
    }

    category_details = ", ".join(
        f"{k}: {len(v)}" for k, v in categorized_tile_folders.items()
    )
    logger.info(f"Categories - {category_details}")
    return categorized_tile_folders


def extract_slide_info(slide_folder_paths: list) -> list:
    """Extract slide information from slide folder name.

    Args:
        slide_folder_paths (list): List of slide folder paths.

    Returns:
        list: Extracted slide informations.
    """
    column_names = [
        "category",
        "slide_name",
        "downsample_rate",
        "img_size",
        "overlap_ratio_per_tile",
        "only_annotated_tiles",
        "allow_partial_tiles",
        "tile_count",
        "mask_count",
    ]

    dataset_entries = []
    for folder_path in slide_folder_paths:
        split_folder_name = folder_path.name.split("|")

        tile_count = len([*(folder_path / "images").iterdir()])
        mask_count = len([*(folder_path / "masks").iterdir()])
        slide_info = dict(
            zip(column_names, split_folder_name + [tile_count, mask_count])
        )
        dataset_entries.append(slide_info)

    return dataset_entries


def extract_location_info(filename: str) -> dict | None:
    """Extract tile location information from tile file name generated by QuPath.

    Args:
        filename (str): Name of the tile.

    Returns:
        dict | None: Extracted location information.
    """
    match = re.search(r"d=([\d.]+).*x=(\d+).*y=(\d+).*w=(\d+).*h=(\d+)", filename)
    if match:
        assert match.group(4) == match.group(5)
        return {
            "downsample_rate": float(match.group(1)),
            "x": match.group(2),
            "y": match.group(3),
            "size_on_slide": match.group(4),
        }
    return None


def extract_tile_info(source: Path, suffix: str = "label", ext: str = "png") -> list:
    """Extract tile & mask information from file name and mask.

    Args:
        source (Path): Directory containing images. Should have masks folder in parent directory to derive mask paths.

    Returns:
        list: All tile & mask information in given source directory.
    """
    tile_info_entries = []

    for item in source.iterdir():
        if item.is_file():
            slide_dir_path = item.parent.parent
            mask_name = f"{item.stem}_{suffix}.{ext}"

            entry = {
                "slide_name": str(slide_dir_path.name),
                "parent_dir_path": str(slide_dir_path),
                "relative_image_path": str(item.relative_to(slide_dir_path)),
                "relative_mask_path": str(Path("masks") / mask_name),
            }

            full_mask_path = slide_dir_path / entry["relative_mask_path"]
            entry["tumor_percentage"] = str(
                image_ops.calculate_tumor_percentage(full_mask_path)
            )
            entry["image_size"] = str(image_ops.get_size(item))

            entry = entry | extract_location_info(item.name)
            tile_info_entries.append(entry)

    return tile_info_entries


def _construct_dataset_list(split: str, tiles: list) -> list:
    """Helper function for split_tiles."""
    return [
        {"slide_name": path.name.split("|")[1], "full_name": path.name, "split": split}
        for path in tiles
    ]


def split_tiles(
    source: Path, train_ratio: float, val_ratio: float, save_dir: Path
) -> Path:
    """Split tiled WSI slides into train-val-test sets virtually. Extract slide and split metadata.

    Args:
        source (Path): Directory containing all tiled slide folders.
        train_ratio (float): Train set ratio. 1 - train_ratio - val_ratio used as test_ratio.
        val_ratio (float): Validation set ratio. 1 - train_ratio - val_ratio used as test_ratio.
        save_dir (Path): CSV file save location.

    Returns:
        Path: Where CSV file is saved.
    """
    categories = categorize_tiles(source)

    logger.info("Creating train-test-split metadata")
    create_test_set = False if np.isclose(train_ratio + val_ratio, 1) else True

    split_entries, slide_info_entries = [], []
    for tile_folders in categories.values():
        np.random.shuffle(tile_folders)
        slide_info_entries.extend(extract_slide_info(tile_folders))

        n_train = int(round(len(tile_folders) * train_ratio))
        n_val = int(round(len(tile_folders) * val_ratio))

        split_entries.extend(_construct_dataset_list("train", tile_folders[:n_train]))

        if create_test_set:
            split_entries.extend(
                _construct_dataset_list("val", tile_folders[n_train : n_train + n_val])
            )
            split_entries.extend(
                _construct_dataset_list("test", tile_folders[n_train + n_val :])
            )
        else:
            split_entries.extend(_construct_dataset_list("val", tile_folders[n_train:]))

    slide_info_path = save_dir / "slide_info.csv"
    utils.save_csv(slide_info_entries, slide_info_path)
    logger.info(f"Slide metadata extracted at {slide_info_path}")

    split_info_path = save_dir / "split.csv"
    utils.save_csv(split_entries, split_info_path)
    logger.info(f"Train-test split metadata extracted at {split_info_path}")

    return split_info_path


def construct_dataset(source: Path, split_info_path: Path, dirs: dict) -> None:
    """Copy files according to CSV file containing split information. Extracts tile metadata.

    Args:
        source (Path): Directory containing all tiled slide folders.
        split_info_path (Path): Location of CSV file containing split information.
        dirs (dict): Saving directories.
    """
    logger.info(f"Started constructing dataset at {dirs['parent']}/")
    split_df = pl.read_csv(split_info_path)
    all_tile_info_entries = []

    pbar = tqdm(
        split_df.iter_rows(named=True),
        total=len(split_df),
        position=0,
        leave=True,
        ncols=100,
    )
    for row_dict in pbar:
        current_slide_name = row_dict["slide_name"]
        pbar.set_description(f"Processing Slides | {utils.pad_str(current_slide_name)}")

        current_path = source / row_dict["full_name"]
        target_path = dirs[row_dict["split"]] / current_slide_name
        shutil.copytree(current_path, target_path)

        target_masks_path = target_path / "masks"
        utils.add_suffix_to_dir_items(target_masks_path)
        tile_info_entries = extract_tile_info(target_path / "images")
        all_tile_info_entries.extend(tile_info_entries)

    tiles_info_path = dirs["metadata"] / "tiles_metadata.csv"
    utils.save_csv(all_tile_info_entries, tiles_info_path)
    logger.info(f"Tile metadata extracted at {split_info_path}")
    logger.info(f"Dataset constructed at {dirs['parent']}/")
